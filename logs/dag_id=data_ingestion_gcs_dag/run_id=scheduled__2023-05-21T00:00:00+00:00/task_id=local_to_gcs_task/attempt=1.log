[2023-05-22 12:55:21,345] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcs_dag.local_to_gcs_task scheduled__2023-05-21T00:00:00+00:00 [queued]>
[2023-05-22 12:55:21,356] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcs_dag.local_to_gcs_task scheduled__2023-05-21T00:00:00+00:00 [queued]>
[2023-05-22 12:55:21,357] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-05-22 12:55:21,358] {taskinstance.py:1357} INFO - Starting attempt 1 of 2
[2023-05-22 12:55:21,358] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-05-22 12:55:21,372] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2023-05-21 00:00:00+00:00
[2023-05-22 12:55:21,377] {standard_task_runner.py:52} INFO - Started process 303 to run task
[2023-05-22 12:55:21,382] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'local_to_gcs_task', 'scheduled__2023-05-21T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs.py', '--cfg-path', '/tmp/tmp_a4lsmjj', '--error-file', '/tmp/tmp6xd4e6kg']
[2023-05-22 12:55:21,383] {standard_task_runner.py:80} INFO - Job 3: Subtask local_to_gcs_task
[2023-05-22 12:55:21,444] {task_command.py:370} INFO - Running <TaskInstance: data_ingestion_gcs_dag.local_to_gcs_task scheduled__2023-05-21T00:00:00+00:00 [running]> on host 5436e4fb5b09
[2023-05-22 12:55:21,525] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcs_dag
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2023-05-21T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-05-21T00:00:00+00:00
[2023-05-22 12:55:21,705] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 171, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 189, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/Users/eugene/Personal_Projects/Data_Project/app/airflow/dags/data_ingestion_gcs.py", line 41, in upload_to_gcs
    blob.upload_from_filename(local_file)
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 2735, in upload_from_filename
    retry=retry,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 2594, in upload_from_file
    retry=retry,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 2412, in _do_upload
    retry=retry,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 2237, in _do_resumable_upload
    retry=retry,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 2112, in _initiate_resumable_upload
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/resumable_media/requests/upload.py", line 421, in initiate
    retriable_request, self._get_status_code, self._retry_strategy
  File "/home/airflow/.local/lib/python3.7/site-packages/google/resumable_media/requests/_request_helpers.py", line 148, in wait_and_retry
    response = func()
  File "/home/airflow/.local/lib/python3.7/site-packages/google/resumable_media/requests/upload.py", line 413, in retriable_request
    method, url, data=payload, headers=headers, timeout=timeout
  File "/home/airflow/.local/lib/python3.7/site-packages/google/auth/transport/requests.py", line 486, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/airflow/.local/lib/python3.7/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/airflow/.local/lib/python3.7/site-packages/google/oauth2/service_account.py", line 411, in refresh
    request, self._token_uri, assertion
  File "/home/airflow/.local/lib/python3.7/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/airflow/.local/lib/python3.7/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/airflow/.local/lib/python3.7/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid grant: account not found', {'error': 'invalid_grant', 'error_description': 'Invalid grant: account not found'})
[2023-05-22 12:55:21,724] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=data_ingestion_gcs_dag, task_id=local_to_gcs_task, execution_date=20230521T000000, start_date=20230522T125521, end_date=20230522T125521
[2023-05-22 12:55:21,736] {standard_task_runner.py:97} ERROR - Failed to execute job 3 for task local_to_gcs_task (('invalid_grant: Invalid grant: account not found', {'error': 'invalid_grant', 'error_description': 'Invalid grant: account not found'}); 303)
[2023-05-22 12:55:21,756] {local_task_job.py:156} INFO - Task exited with return code 1
[2023-05-22 12:55:21,798] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-22 14:15:44,177] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcs_dag.local_to_gcs_task scheduled__2023-05-21T00:00:00+00:00 [queued]>
[2023-05-22 14:15:44,189] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcs_dag.local_to_gcs_task scheduled__2023-05-21T00:00:00+00:00 [queued]>
[2023-05-22 14:15:44,191] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-05-22 14:15:44,192] {taskinstance.py:1357} INFO - Starting attempt 1 of 2
[2023-05-22 14:15:44,193] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-05-22 14:15:44,212] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2023-05-21 00:00:00+00:00
[2023-05-22 14:15:44,219] {standard_task_runner.py:52} INFO - Started process 281 to run task
[2023-05-22 14:15:44,224] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'local_to_gcs_task', 'scheduled__2023-05-21T00:00:00+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs.py', '--cfg-path', '/tmp/tmpbpsf_o3b', '--error-file', '/tmp/tmpia_pm41h']
[2023-05-22 14:15:44,226] {standard_task_runner.py:80} INFO - Job 15: Subtask local_to_gcs_task
[2023-05-22 14:15:44,324] {task_command.py:370} INFO - Running <TaskInstance: data_ingestion_gcs_dag.local_to_gcs_task scheduled__2023-05-21T00:00:00+00:00 [running]> on host bfd57a4116d5
[2023-05-22 14:15:44,426] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcs_dag
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2023-05-21T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-05-21T00:00:00+00:00
[2023-05-22 14:15:44,694] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 2594, in upload_from_file
    retry=retry,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 2412, in _do_upload
    retry=retry,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 2237, in _do_resumable_upload
    retry=retry,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 2112, in _initiate_resumable_upload
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/resumable_media/requests/upload.py", line 421, in initiate
    retriable_request, self._get_status_code, self._retry_strategy
  File "/home/airflow/.local/lib/python3.7/site-packages/google/resumable_media/requests/_request_helpers.py", line 148, in wait_and_retry
    response = func()
  File "/home/airflow/.local/lib/python3.7/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.7/site-packages/google/resumable_media/_upload.py", line 513, in _process_initiate_response
    callback=self._make_invalid,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/resumable_media/_helpers.py", line 110, in require_status_code
    *status_codes
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 403, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 171, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 189, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/Users/eugene/Personal_Projects/Data_Project/app/airflow/dags/data_ingestion_gcs.py", line 41, in upload_to_gcs
    blob.upload_from_filename(local_file)
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 2735, in upload_from_filename
    retry=retry,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 2598, in upload_from_file
    _raise_from_invalid_response(exc)
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 4470, in _raise_from_invalid_response
    raise exceptions.from_http_status(response.status_code, message, response=response)
google.api_core.exceptions.Forbidden: 403 POST https://storage.googleapis.com/upload/storage/v1/b/twitter-etl-bucket/o?uploadType=resumable: {
  "error": {
    "code": 403,
    "message": "690814178061-compute@developer.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist).",
    "errors": [
      {
        "message": "690814178061-compute@developer.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist).",
        "domain": "global",
        "reason": "forbidden"
      }
    ]
  }
}
: ('Request failed with status code', 403, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)
[2023-05-22 14:15:44,710] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=data_ingestion_gcs_dag, task_id=local_to_gcs_task, execution_date=20230521T000000, start_date=20230522T141544, end_date=20230522T141544
[2023-05-22 14:15:44,724] {standard_task_runner.py:97} ERROR - Failed to execute job 15 for task local_to_gcs_task (403 POST https://storage.googleapis.com/upload/storage/v1/b/twitter-etl-bucket/o?uploadType=resumable: {
  "error": {
    "code": 403,
    "message": "690814178061-compute@developer.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist).",
    "errors": [
      {
        "message": "690814178061-compute@developer.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist).",
        "domain": "global",
        "reason": "forbidden"
      }
    ]
  }
}
: ('Request failed with status code', 403, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>); 281)
[2023-05-22 14:15:44,764] {local_task_job.py:156} INFO - Task exited with return code 1
[2023-05-22 14:15:44,805] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-22 14:24:15,081] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcs_dag.local_to_gcs_task scheduled__2023-05-21T00:00:00+00:00 [queued]>
[2023-05-22 14:24:15,092] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcs_dag.local_to_gcs_task scheduled__2023-05-21T00:00:00+00:00 [queued]>
[2023-05-22 14:24:15,093] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-05-22 14:24:15,094] {taskinstance.py:1357} INFO - Starting attempt 1 of 2
[2023-05-22 14:24:15,094] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-05-22 14:24:15,108] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2023-05-21 00:00:00+00:00
[2023-05-22 14:24:15,114] {standard_task_runner.py:52} INFO - Started process 525 to run task
[2023-05-22 14:24:15,118] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'local_to_gcs_task', 'scheduled__2023-05-21T00:00:00+00:00', '--job-id', '20', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs.py', '--cfg-path', '/tmp/tmpz0y4x7y1', '--error-file', '/tmp/tmpgff1w1ed']
[2023-05-22 14:24:15,119] {standard_task_runner.py:80} INFO - Job 20: Subtask local_to_gcs_task
[2023-05-22 14:24:15,179] {task_command.py:370} INFO - Running <TaskInstance: data_ingestion_gcs_dag.local_to_gcs_task scheduled__2023-05-21T00:00:00+00:00 [running]> on host bfd57a4116d5
[2023-05-22 14:24:15,256] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcs_dag
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2023-05-21T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-05-21T00:00:00+00:00
[2023-05-22 14:24:15,490] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 2594, in upload_from_file
    retry=retry,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 2412, in _do_upload
    retry=retry,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 2237, in _do_resumable_upload
    retry=retry,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 2112, in _initiate_resumable_upload
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/resumable_media/requests/upload.py", line 421, in initiate
    retriable_request, self._get_status_code, self._retry_strategy
  File "/home/airflow/.local/lib/python3.7/site-packages/google/resumable_media/requests/_request_helpers.py", line 148, in wait_and_retry
    response = func()
  File "/home/airflow/.local/lib/python3.7/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.7/site-packages/google/resumable_media/_upload.py", line 513, in _process_initiate_response
    callback=self._make_invalid,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/resumable_media/_helpers.py", line 110, in require_status_code
    *status_codes
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 403, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 171, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 189, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/Users/eugene/Personal_Projects/Data_Project/app/airflow/dags/data_ingestion_gcs.py", line 41, in upload_to_gcs
    blob.upload_from_filename(local_file)
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 2735, in upload_from_filename
    retry=retry,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 2598, in upload_from_file
    _raise_from_invalid_response(exc)
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 4470, in _raise_from_invalid_response
    raise exceptions.from_http_status(response.status_code, message, response=response)
google.api_core.exceptions.Forbidden: 403 POST https://storage.googleapis.com/upload/storage/v1/b/twitter-etl-bucket/o?uploadType=resumable: {
  "error": {
    "code": 403,
    "message": "690814178061-compute@developer.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist).",
    "errors": [
      {
        "message": "690814178061-compute@developer.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist).",
        "domain": "global",
        "reason": "forbidden"
      }
    ]
  }
}
: ('Request failed with status code', 403, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)
[2023-05-22 14:24:15,507] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=data_ingestion_gcs_dag, task_id=local_to_gcs_task, execution_date=20230521T000000, start_date=20230522T142415, end_date=20230522T142415
[2023-05-22 14:24:15,519] {standard_task_runner.py:97} ERROR - Failed to execute job 20 for task local_to_gcs_task (403 POST https://storage.googleapis.com/upload/storage/v1/b/twitter-etl-bucket/o?uploadType=resumable: {
  "error": {
    "code": 403,
    "message": "690814178061-compute@developer.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist).",
    "errors": [
      {
        "message": "690814178061-compute@developer.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist).",
        "domain": "global",
        "reason": "forbidden"
      }
    ]
  }
}
: ('Request failed with status code', 403, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>); 525)
[2023-05-22 14:24:15,532] {local_task_job.py:156} INFO - Task exited with return code 1
[2023-05-22 14:24:15,574] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
